{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.special import comb\n",
    "from torch import nn\n",
    "import torch.nn.functional as nnf\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ProjectiveSpatialTransformer(nn.Module):\n",
    "    def __init__(self,size,edge=1):\n",
    "        super(ProjectiveSpatialTransformer, self).__init__()\n",
    "        \n",
    "        self.size=size\n",
    "\n",
    "        self.edge=edge\n",
    "        #To eliminate rounding errors at the boundaries, exclude the boundary regions from calculations. \n",
    "        #If your data contains non-background elements at the boundaries, you can set them to zero.\n",
    "        \n",
    "        # create sampling grid\n",
    "        vectors = [torch.arange(0, s) for s in size]\n",
    "        grids = torch.meshgrid(vectors)\n",
    "        grid = torch.stack(grids)\n",
    "        grid = torch.unsqueeze(grid, 0)\n",
    "        grid = grid.type(torch.FloatTensor)\n",
    "\n",
    "        # registering the grid as a buffer cleanly moves it to the GPU, but it also\n",
    "        # adds it to the state dict. this is annoying since everything in the state dict\n",
    "        # is included when saving weights to disk, so the model files are way bigger\n",
    "        # than they need to be. so far, there does not appear to be an elegant solution.\n",
    "        # see: https://discuss.pytorch.org/t/how-to-register-buffer-without-polluting-state-dict\n",
    "        self.register_buffer('grid', grid)\n",
    "        \n",
    "\n",
    "    def add_view(self,sam,int_locs,value): \n",
    "       \n",
    "        B,C,H,W,D=int_locs.shape\n",
    "        assert B==1\n",
    "        # sam_flat = sam.contiguous().view(-1)\n",
    "        # value_flat=value.contiguous().view(-1)\n",
    "        sam_flat = sam.view(-1)\n",
    "        value_flat=value.view(-1)\n",
    "        #int_locs B 3 H W D\n",
    "        Shape=(H,W,D)\n",
    "        for i in range(len(Shape)):\n",
    "            slice=int_locs[:,i,...]\n",
    "            slice[int_locs[:,i,...]>=(Shape[i]-1)]=Shape[i]-1\n",
    "            \n",
    "        int_locs = int_locs.view(3,-1)\n",
    "        int_locs_flat=int_locs[0]*W*D+int_locs[1]*D+int_locs[2]\n",
    "        sam_flat.scatter_add_(0, int_locs_flat, value_flat)\n",
    "        sam_flat = sam_flat.view(sam.shape)\n",
    "        return sam_flat\n",
    "    def forward(self, src, flow, mode='bilinear'):\n",
    "        shape = flow.shape[2:]\n",
    "\n",
    "        # To test whether three components correspond to dx, dy, and dz, \n",
    "        # flow[:,0,...]=2#(shape[0]-1)\n",
    "        # flow[:,1,...]=-7#(shape[1]-1)\n",
    "        # flow[:,2,...]=0#(shape[2]-1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.grid = self.grid.cuda()\n",
    "        locs=self.grid + flow\n",
    "        \n",
    "        \n",
    "        locs[locs<=0]=0 \n",
    "        int_locs=torch.floor(locs).type(torch.int64)\n",
    "        delta_locs=locs-int_locs\n",
    "        \n",
    "        new_src=torch.zeros_like(src)\n",
    "  \n",
    "        #000\n",
    "        new_src= self.add_view(new_src,int_locs, src*(1-delta_locs[:,0:1,...])*(1-delta_locs[:,1:2,...])*(1-delta_locs[:,2:3,...]))\n",
    "        #100\n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...]+1,int_locs[:, 1:2, ...],int_locs[:, 2:3, ...]),dim=1), \n",
    "                          src*(delta_locs[:,0:1,...])*(1-delta_locs[:,1:2,...])*(1-delta_locs[:,2:3,...]))       \n",
    "        #010 \n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...],int_locs[:, 1:2, ...]+1,int_locs[:, 2:3, ...]),dim=1), \n",
    "                          src*(1-delta_locs[:,0:1,...])*(delta_locs[:,1:2,...])*(1-delta_locs[:,2:3,...]))\n",
    "        #001\n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...],int_locs[:, 1:2, ...],int_locs[:, 2:3, ...]+1),dim=1), \n",
    "                          src*(1-delta_locs[:,0:1,...])*(1-delta_locs[:,1:2,...])*(delta_locs[:,2:3,...]))\n",
    "        #110\n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...]+1,int_locs[:, 1:2, ...]+1,int_locs[:, 2:3, ...]),dim=1), \n",
    "                          src*(delta_locs[:,0:1,...])*(delta_locs[:,1:2,...])*(1-delta_locs[:,2:3,...]))\n",
    "        #101\n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...]+1,int_locs[:, 1:2, ...],int_locs[:, 2:3, ...]+1),dim=1), \n",
    "                          src*(delta_locs[:,0:1,...])*(1-delta_locs[:,1:2,...])*(delta_locs[:,2:3,...]))\n",
    "        #011\n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...],int_locs[:, 1:2, ...]+1,int_locs[:, 2:3, ...]+1),dim=1), \n",
    "                          src*(1-delta_locs[:,0:1,...])*(delta_locs[:,1:2,...])*(delta_locs[:,2:3,...]))\n",
    "        #111\n",
    "        new_src= self.add_view(new_src,torch.cat((int_locs[:, 0:1,...]+1,int_locs[:, 1:2, ...]+1,int_locs[:, 2:3, ...]+1),dim=1), \n",
    "                          src*(delta_locs[:,0:1,...])*(delta_locs[:,1:2,...])*(delta_locs[:,2:3,...]))\n",
    "        \n",
    "        # The following implementation is non-differentiable, and I was troubled by this bug for a long time. \n",
    "        # If you need to modify the program for a batch size greater than 1, \n",
    "        # I hope you can avoid this implementation approach in advance.\n",
    "        # new_src[:, \n",
    "        #         :,\n",
    "        #         int_locs[0, 0, :, :, :], \n",
    "        #         int_locs[0, 1, :, :, :],\n",
    "        #         int_locs[0, 2, :, :, :]] = src*(1-delta_locs[:,0:1,...])*(1-delta_locs[:,1:2,...])*(1-delta_locs[:,2:3,...])\n",
    "\n",
    "        return new_src\n",
    "    \n",
    "    def gradient_loss(self,s, penalty='l2'):\n",
    "        dy = torch.abs(s[:, :, 1:, :, :] - s[:, :, :-1, :, :]) \n",
    "        dx = torch.abs(s[:, :, :, 1:, :] - s[:, :, :, :-1, :]) \n",
    "        dz = torch.abs(s[:, :, :, :, 1:] - s[:, :, :, :, :-1]) \n",
    "\n",
    "        if(penalty == 'l2'):\n",
    "            dy = dy * dy\n",
    "            dx = dx * dx\n",
    "            dz = dz * dz\n",
    "\n",
    "        d = torch.mean(dx) + torch.mean(dy) + torch.mean(dz)\n",
    "        return d / 3.0\n",
    "    \n",
    "    def loss_spim1(self,flow):\n",
    "        ones=torch.ones(self.size).unsqueeze(0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            ones=ones.cuda()\n",
    "        return torch.mean((self.forward(ones,flow)[:,:,self.edge:self.size[0]-self.edge,\n",
    "                                                   self.edge:self.size[1]-self.edge,\n",
    "                                                   self.edge:self.size[2]-self.edge]-\n",
    "                                         ones[:,:,self.edge:self.size[0]-self.edge,\n",
    "                                                   self.edge:self.size[1]-self.edge,\n",
    "                                                   self.edge:self.size[2]-self.edge])**2)\n",
    "    def loss_focal_spim1(self,flow,focal_weight):\n",
    "        ones=torch.ones(self.size).unsqueeze(0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            ones=ones.cuda()\n",
    "        \n",
    "        return torch.sum(((self.forward(ones,flow)-ones)**2)*focal_weight)/torch.sum(focal_weight>0.15)\n",
    "    \n",
    "    def loss_spim2(self,flow):\n",
    "        ones=torch.ones(self.size).unsqueeze(0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            ones=ones.cuda()\n",
    "            \n",
    "        return self.gradient_loss(self.forward(ones,flow)[:,:,self.edge:self.size[0]-self.edge,\n",
    "                                                   self.edge:self.size[1]-self.edge,\n",
    "                                                   self.edge:self.size[2]-self.edge])\n",
    "    #def loss_k(self,flow):\n",
    "    #def loss_k100(self,flow):\n",
    "    #def loss_log(self,flow):\n",
    "\n",
    "    def extreme_sampling_probability(self,flow,threshold_l=0.3,threshold_r=1.7):\n",
    "        ones=torch.ones(self.size).unsqueeze(0).unsqueeze(0)\n",
    "        if torch.cuda.is_available():\n",
    "            ones=ones.cuda()\n",
    "            print(ones.requires_grad,'....')\n",
    "        SP=self.forward(ones,flow)[:,:,self.edge:self.size[0]-self.edge,\n",
    "                                                   self.edge:self.size[1]-self.edge,\n",
    "                                                   self.edge:self.size[2]-self.edge]\n",
    "        return (SP<threshold_l).sum()+(SP>threshold_r).sum()\n",
    "\n",
    "# Initialization\n",
    "inshape=(160,192,224)\n",
    "PSTN =ProjectiveSpatialTransformer(inshape)\n",
    "ones=torch.ones(inshape).unsqueeze(0).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "fixed=nib.load('./data/exp2/test1/00000fixed_image.nii.gz').get_fdata().squeeze()\n",
    "moving=nib.load('./data/exp2/test1/00000moving_image.nii.gz').get_fdata().squeeze()\n",
    "flow=nib.load('./data/exp2/test1/00000flow.nii.gz').get_fdata().squeeze()\n",
    "warped=nib.load('./data/exp2/test1/00000warped_image.nii.gz').get_fdata().squeeze()\n",
    "\n",
    "flow1=torch.tensor(flow).unsqueeze(0).permute(0,4,1,2,3).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    flow1=flow1.cuda()\n",
    "    ones=ones.cuda()\n",
    "# Generate Sampling Frequency Map (SFM)\n",
    "sfm=PSTN(ones,flow1).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "slice=100\n",
    "fig, axes = plt.subplots(2, 3)\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(moving[:,:,slice])\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(fixed[:,:,slice])\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(warped[:,:,slice])\n",
    "\n",
    "temp=sfm[:,:,slice]\n",
    "temp[temp>2]=2\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(temp,cmap='jet')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(flow1[0,0,:,:,slice])\n",
    "\n",
    "titles = ['Moving', 'Fixed', 'Warped', 'SFM', 'Flow']\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i<5:  \n",
    "        ax.set_title(titles[i])\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
